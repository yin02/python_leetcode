1. 定义 DP 数组
2. 递推公式,state transfer
3. DP 数组初始化
4. 遍历顺序
5. 举例推导dp数组

定函初遍举（）



是的，大模型算法中 **动态规划 (DP)** 和 **图论** 是非常常用的核心算法类别，但并不局限于这两类。以下是一些大模型开发或优化中常用的算法类别及其应用场景：

---

### **1. 动态规划 (DP)**
**用途**：  
- **序列优化**：例如 Transformer 模型中的序列建模和路径优化问题。  
- **概率分布计算**：如 HMM（隐马尔可夫模型）的前向后向算法。  
- **优化问题**：如优化训练超参数或减少模型推理时间。

**应用场景**：  
- 自然语言处理 (NLP)：文本对齐（如机器翻译中的动态规划方法）。  
- 模型剪枝：对参数选择或模型结构优化时用到 DP 思想。  

**为什么重要**：  
动态规划能够有效解决状态之间有依赖关系的问题，特别适合优化问题和分阶段决策的问题。

---

### **2. 图论**
**用途**：  
- **知识图谱 (Knowledge Graph)**：存储和搜索实体间关系。  
- **最短路径与网络流**：例如模型数据传输路径优化。  
- **大规模分布式计算**：节点关系建模和图结构优化。  

**应用场景**：  
- 图神经网络 (Graph Neural Networks, GNNs)：如 GCN、GAT 等用于建模图结构数据。  
- 数据流分配：分布式训练中的任务调度。  
- 推荐系统：基于图的协同过滤算法。  

**为什么重要**：  
大模型通常需要处理复杂的关系型数据，图论为建模这些关系提供了基础。

---

### **3. 贪心算法 (Greedy Algorithm)**
**用途**：  
- **模型压缩**：通过贪心策略选择最重要的参数进行剪枝。  
- **任务调度**：分布式训练任务的资源分配问题。

**应用场景**：  
- 高效推理优化：如大模型部署时的算力资源最优利用。  
- 参数选择：基于梯度下降等的贪心更新策略。

---

### **4. 线性代数与矩阵操作**
**用途**：  
- **矩阵运算优化**：如大模型中的权重更新（Transformer 的核心矩阵操作）。  
- **特征提取**：如奇异值分解（SVD）、主成分分析（PCA）。  

**应用场景**：  
- 模型训练：高效实现前向传播和反向传播。  
- 模型压缩：降维技术减少存储开销。

**为什么重要**：  
几乎所有的深度学习模型都涉及矩阵操作，因此线性代数是底层核心。

---

### **5. 搜索与剪枝 (Search & Pruning)**
**用途**：  
- **超参数调优**：网格搜索、随机搜索或进化算法优化模型。  
- **推理优化**：如 Beam Search 用于语言生成任务。  

**应用场景**：  
- NLP：生成式模型中的句子搜索和最佳序列生成。  
- 神经架构搜索 (NAS)：搜索最佳模型结构。

---

### **6. 数学优化与凸优化**
**用途**：  
- **损失函数优化**：如梯度下降、Adam 等优化算法。  
- **模型训练加速**：基于凸优化理论设计的高效优化器。

**应用场景**：  
- 模型收敛：确保模型能够快速且稳定地达到目标损失。  
- 多目标优化：权衡模型性能和资源开销。

---

### **7. 其他辅助算法**
1. **Trie 树**  
   - **用途**：用于快速查找和匹配（如词汇表构建）。  
2. **堆 (Heap)**  
   - **用途**：优化优先级队列相关问题（如任务调度）。  
3. **并查集 (Union-Find)**  
   - **用途**：解决连通性问题，常用于多节点任务分配。

---

### **总结**
- **最常用的确是 DP 和 图论**，因为它们直接对应了大模型的核心场景（如优化和关系建模）。  
- **其他类别**（如线性代数、搜索、数学优化）也是不可或缺的基础，特别是在提升训练速度、减少资源占用时非常关键。

想针对某类算法或大模型的具体应用场景深入学习，随时可以告诉我！